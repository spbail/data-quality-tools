{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "touched-isaac",
   "metadata": {},
   "source": [
    "# The Wonderful World of Data Quality Tools in Python\n",
    "Sam Bail, Data Umbrella, March 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-crime",
   "metadata": {},
   "source": [
    "## Imports and data loading\n",
    "We've got some CSV files with 10,000 row samples of NYC taxi ride data from January and February 2019 which I'm loading here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "perceived-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "backed-affairs",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/yellow_tripdata_sample_2019-01.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d9de8fd95392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcsv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/yellow_tripdata_sample_2019-01.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/dq/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/dq/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/dq/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/dq/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/dq/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/dq/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/dq/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/yellow_tripdata_sample_2019-01.csv'"
     ]
    }
   ],
   "source": [
    "csv1 = 'data/yellow_tripdata_sample_2019-01.csv'\n",
    "df1 = pd.read_csv(csv1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv2 = 'data/yellow_tripdata_sample_2019-02.csv'\n",
    "df2 = pd.read_csv(csv2)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-subject",
   "metadata": {},
   "source": [
    "## Example 1: Pandas \"describe\" for DataFrames\n",
    "A simple \"profiler\" for dataframes. It just gives you some basic statistics on numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-declaration",
   "metadata": {},
   "source": [
    "# Example 2: Pandas Profiling\n",
    "Like a very sophisticated extension of .describe() on Pandas dataframes, \n",
    "creates a more detailed profile report of the data.\n",
    "\n",
    "**Note:** The key difference between the two dataframes is the minimum in the *passenger_count* column:\n",
    "* In the January data (df1), we have passenger counts from 1 through 6. \n",
    "* In the February data (df2), we have counts from 0 through 6, which looks like a bug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple way to profile our dataframe and look at the nicely rendered HTML result\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "ProfileReport(df1, title=\"Pandas Profiling Report for df1\").to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProfileReport(df2, title=\"Pandas Profiling Report for df2\").to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-captain",
   "metadata": {},
   "source": [
    "# Example 3: TDDA (Test-Driven Data Analysis)\n",
    "TDDA allows us to generate \"constraints\" from a reference data asset and verify whether another data asset matches those constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-steps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the constraints based on the January dataframe\n",
    "\n",
    "from tdda.constraints import discover_df, verify_df\n",
    "constraints = discover_df(df1)\n",
    "constraints_path = 'tdda_refs/example_constraints.tdda'\n",
    "with open(constraints_path, 'w') as f:\n",
    "    f.write(constraints.to_json())\n",
    "    \n",
    "# Show the generated constraints\n",
    "print(str(constraints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-prefix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the January data matches the constraints - this should match of course!\n",
    "\n",
    "v1 = verify_df(df1, constraints_path, type_checking='strict', epsilon=0)\n",
    "print(str(v1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the February data matches the constraints - this should fail\n",
    "# because we have a different min for passenger_count\n",
    "\n",
    "v2 = verify_df(df2, constraints_path, type_checking='strict', epsilon=0)\n",
    "print(str(v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-collaboration",
   "metadata": {},
   "source": [
    "## Example 4: Bulwark\n",
    "Data testing framework that lets you add tests on methods that return Pandas dataframes. \n",
    "Has some built-in tests and allows custom methods for tests. List of all built-in tests (\"checks\"): https://bulwark.readthedocs.io/en/stable/bulwark.checks.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bulwark.decorators as dc\n",
    "\n",
    "# Option 1: Add checks/assertions as decorators on methods that generate dataframes\n",
    "# This will return the df if all tests pass, and raise errors if any of the tests fail\n",
    "@dc.HasNoNans()\n",
    "@dc.IsShape((10000, 5)) # 10000 rows, 5 columns\n",
    "@dc.HasValsWithinRange(items={\"passenger_count\": (1,6)}) # min and max are inclusive here\n",
    "def load_and_test_csv(csv_file_path):\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    return df\n",
    "\n",
    "# Test this out with the January data\n",
    "load_and_test_csv(csv1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's test the February data - this should fail the \"has vals within range\" test\n",
    "load_and_test_csv(csv2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bulwark.checks as ck\n",
    "\n",
    "# Option 2: You can also use the built-in tests (\"checks\") directly on a dataframe\n",
    "ck.is_shape(df2, (10000, 5)).head() # 10000 rows, 5 columns\n",
    "ck.has_vals_within_range(df2, items={\"passenger_count\": (1,6)}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-drawing",
   "metadata": {},
   "source": [
    "## Example 5: Voluptous/Opulent Pandas\n",
    "Voluptous is a data validation library that allows you to specify a \"schema\" to validate JSON/YAML. \n",
    "Opulent Pandas is a df-focused “version” of Voluptuous. The syntax to define and validate a schema\n",
    "is very similar. \n",
    "\n",
    "**Note:** Opulent Pandas doesn't look like it's being actively maintained, so I'm\n",
    "only showing Voluptuous here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from voluptuous import All, Range, ALLOW_EXTRA\n",
    "\n",
    "# I had to fiddle a little to pass the right dict-type data structure into the schema\n",
    "# This returns the df if the tests pass, or throws an error if a test fails \n",
    "def validate_df(df):\n",
    "    schema = Schema(\n",
    "        {\n",
    "            'vendor_id': All(int)\n",
    "            'passenger_count': All(int, Range(min=1, max=6))\n",
    "        }, \n",
    "        extra=ALLOW_EXTRA\n",
    "    )\n",
    "    for r in df.to_dict('records'):\n",
    "        schema(r)\n",
    "    return df\n",
    "\n",
    "# Test this out with df1, which should pass\n",
    "validate_df(df1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-fortune",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_df(df2).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-dating",
   "metadata": {},
   "source": [
    "## Example 6: mobydq\n",
    "\n",
    "Data validation web app that allows you to check for \"indicators\" such as completeness, freshness, latency, validity.\n",
    "Only showing a screenshot here because the setup is pretty heavyweight.\n",
    "\n",
    "![mobydq](img/mobydq_screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-trace",
   "metadata": {},
   "source": [
    "## Example 7: dvc (data version control)\n",
    "Command-line tool, showing screenshots.\n",
    "\n",
    "\n",
    "![dvc init](img/dvc_init.png)\n",
    "![dvc add](img/dvc_add.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-wilson",
   "metadata": {},
   "source": [
    "You can then make modifications to data files and commit new versions and check out previous versions, \n",
    "all controlled via the .dvc file. \n",
    "dvc also allows you to set remotes to sync data to (instead of managing the actual data via GitHub), e.g. S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-harvest",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
